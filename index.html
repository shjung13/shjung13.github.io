<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Sanghun Jung</title>
  
  <meta name="author" content="Sanghun Jung">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!--link rel="icon" type="image/png" href="images/seal_icon.png"-->
</head>

<body>
  <table style="width:100%;max-width:870px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Sanghun Jung</name>
              </p><br>
              <p>I am a third-year PhD student at the University of Washington, where I am advised by Byron Boots. I am interested in visual learning for robotics, bridging the gap between visual perception and robot planning/control.
              My recent research covers general robot perceptions problems in off-road navigation including traversability prediction from visual cues by self-supervision and representation learning from LiDAR and images.
              </p>
              <p style="text-align:center">
                Mail: shjung13 [at] cs [dot] washington [dot] edu
              </p>
              <p style="text-align:center">
                <a href="data/CV_SanghunJung_08062025.pdf">CV</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/sanghun-jung-b17a4b1b8/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=e7X7O8gAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/shjung13/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/SanghunJung.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/SanghunJung_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <!--table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding-left:20px;padding-bottom:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
            </td>
          </tr>
        </tbody></table-->
        <!--table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="data/SML.png"><img src="images/SML.png" alt="ICCV_Best_Poster" width="200"></a>
            </td>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle></papertitle>
              <a href="https://arxiv.org/abs/2107.11264"> [paper] </a>
            </td>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle>[Best Poster Awards] Our paper "Standardized Max Logits" won the Best Poster Awards at KAIST AI Conference!</papertitle>
              <a href="https://arxiv.org/abs/2107.11264"> [paper] </a>
            </td>
          </tr>
          <tr> 
          <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="data/ICCV_interview.pdf"><img src="images/ICCV_interview1.png" alt="ICCV_interview" width="200"></a>
            </td>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle>[Interview] Jungsoo and I had an interview at ICCV Daily magazine about our recent paper!</papertitle><br>
              <a href="data/ICCV_interview.pdf"> [article] </a>
            </td>
          </tr>
        </tbody></table-->
        <hr class="soft">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr> <!-- bgcolor="#ffffd0"-->
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="images/racer.png"><img src="images/racer.png" alt="RACER Project" width="200"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>DARPA Robotic Autonomy in Complex Environments with Resiliency (RACER)</papertitle>
                <div style="line-height:50%;">
                    <br>
                </div>
              University of Washington, 2023
              <br>
              <!--a href="https://arxiv.org/abs/2112.03517">arXiv</a-->
            </td>
          </tr>

          <tr> <!-- bgcolor="#ffffd0"-->
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="images/MPAIL.png"><img src="images/MPAIL.png" alt="MPAIL" width="200"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Model Predictive Adversarial Imitation Learning for Planning from Observation</papertitle>
                <div style="line-height:50%;">
                    <br>
                </div>
              Tyler Han, Yanda Bao, Bhaumik Mehta, Gabriel Guo, Anubhav Vishwakarma, Emily Kang, <u><strong>Sanghun Jung</strong></u>, Rosario Scalise, Jason Zhou, Bryan Xu, and Byron Boots
              <br>
              <em>Preprint</em>, 2025 &nbsp
              <br>
              <a href="https://arxiv.org/abs/2507.21533">arXiv</a>
            </td>
          </tr>
          <tr> <!-- bgcolor="#ffffd0"-->
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="images/SCNP.png"><img src="images/SCNP.png" alt="Terrain Elevation Modeling" width="200"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Uncertainty-aware Accurate Elevation Modeling for Off-road Navigation via Neural Processes</papertitle>
                <div style="line-height:50%;">
                    <br>
                </div>
              <u><strong>Sanghun Jung</strong></u>, Daehoon Gwak, Byron Boots, and James Hays
              <br>
              <strong><em>CoRL</em></strong>, 2025 &nbsp
              <br>
              <a href="https://arxiv.org/abs/2508.03890">arXiv</a>
            </td>
          </tr>

          <tr> <!-- bgcolor="#ffffd0"-->
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="images/WheeledLab.png"><img src="images/WheeledLab.png" alt="WheeledLab" width="200"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Demonstrating Wheeled Lab: Modern Sim2Real for Low-cost, Open-source Wheeled Robotics</papertitle>
                <div style="line-height:50%;">
                    <br>
                </div>
              Tyler Han, Preet Shah, Sidharth Rajagopal, Yanda Bao, <u><strong>Sanghun Jung</strong></u>, Sidharth Talia, Gabriel Guo, Bryan Xu, Bhaumik Mehta, Emma Romig, Rosario Scalise, and Byron Boots
              <br>
              <strong><em>CoRL</em></strong>, 2025 &nbsp
              <br>
              <a href="https://arxiv.org/abs/2502.07380">arXiv</a>
            </td>
          </tr>
          <tr> <!-- bgcolor="#ffffd0"-->
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="images/OV3DIS.jpeg"><img src="images/OV3DIS.jpeg" alt="OV-3DIS" width="200"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Details Matter for Indoor Open-vocabulary 3D Instance Segmentation</papertitle>
                <div style="line-height:50%;">
                    <br>
                </div>
              <u><strong>Sanghun Jung</strong></u>, Jingjing Zheng, Ke Zhang, Nan Qiao, Albert Y. C. Chen, Lu Xia, Chi Liu, Yuyin Sun, Xiao Zeng, Hsiang-Wei Huang, Byron Boots, Min Sun, and Cheng-Hao Kuo
              <br>
              <strong><em>ICCV</em></strong>, 2025 &nbsp
              <br>
              <a href="http://arxiv.org/abs/2507.23134">arXiv</a>
            </td>
          </tr>

          <tr> <!-- bgcolor="#ffffd0"-->
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="images/dtc.png"><img src="images/dtc.png" alt="Dynamic Token Compression" width="200"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Zero-shot 3D Question Answering via Voxel-based Dynamic Token Compression</papertitle>
                <div style="line-height:50%;">
                    <br>
                </div>
              Hsiang-Wei Huang, Fu-Chen Chen, Wenhao Chai, Che-Chun Su, Lu Xia, <u><strong>Sanghun Jung</strong></u>, Cheng-Yen Yang, Jenq-Neng Hwang, Min Sun, and Cheng-Hao Kuo
              <br>
              <strong><em>CVPR</em></strong>, 2025 &nbsp
              <br>
              <a href="https://www.amazon.science/publications/zero-shot-3d-question-answering-via-voxel-based-dynamic-token-compression">paper</a>
            </td>
          </tr>
          <tr> <!-- bgcolor="#ffffd0"-->
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="images/AMR.png"><img src="images/AMR.png" alt="Overview of AMR" width="200"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Aim My Robot: Precision Local Navigation to Any Object</papertitle>
                <div style="line-height:50%;">
                    <br>
                </div>
              Xiangyun Meng, Xuning Yang, <u><strong>Sanghun Jung</strong></u>, Fabio Ramos, Srid Sadhan Jujjavarapu, Sanjoy Paul, and Dieter Fox
              <br>
              <strong><em>RA-L</em></strong>, 2025 &nbsp
              <br>
              <a href="https://arxiv.org/abs/2411.14770">arXiv</a>
            </td>
          </tr>

          <tr> <!-- bgcolor="#ffffd0"-->
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="images/traversability.png"><img src="images/traversability.png" alt="Visual traversability prediction" width="200"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>V-STRONG: Visual Self-Supervised Traversability Learning for Off-road Navigation</papertitle>
                <div style="line-height:50%;">
                    <br>
                </div>
              <u><strong>Sanghun Jung</strong></u>, JoonHo Lee, Xiangyun Meng, Byron Boots, and Alexander Lambert
              <br>
              <strong><em>ICRA</em></strong>, 2024 &nbsp
              <br>
              <a href="https://arxiv.org/abs/2312.16016">arXiv</a>
              <!--a href="https://arxiv.org/abs/2112.03517">arXiv</a-->
            </td>
          </tr>
          <tr> <!-- bgcolor="#ffffd0"-->
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="images/lidaruda.png"><img src="images/lidaruda.png" alt="LiDAR-UDA" width="200"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>LiDAR-UDA: Self-ensembling Through Time for Unsupervised LiDAR Domain Adaptation</papertitle>
                <div style="line-height:50%;">
                    <br>
                </div>
              Amirreza Shaban*, JoonHo Lee*, <u><strong>Sanghun Jung*</strong></u>, Xiangyun Meng, and Byron Boots
              <br>
              <strong><em>ICCV</em></strong>, 2023 &nbsp  <font color="red"><strong>Oral Presentation (<1.8%)</strong></font>

              <br>
              <a href="https://arxiv.org/abs/2309.13523">arXiv</a>
              /
              <a href="https://github.com/JHLee0513/LiDARUDA">code</a>
            </td>
          </tr>
          <tr> <!-- bgcolor="#ffffd0"-->
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="images/cafa.png"><img src="images/cafa.png" alt="Class-aware Feature Alignment" width="200"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>CAFA: Class-aware Feature Alignment for Test-time Adaptation</papertitle>
              <div style="line-height:50%;">
                  <br>
              </div>
              <u><strong>Sanghun Jung</strong></u>, Jungsoo Lee, Nanhee Kim, Amirreza Shaban, Byron Boots, and Jaegul Choo
              <br>
              <strong><em>ICCV</em></strong>, 2023 &nbsp
              <br>
              <a href="https://arxiv.org/abs/2206.00205">arXiv</a>
            </td>
          </tr>
          <tr> <!-- bgcolor="#ffffd0"-->
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="images/debiasing.png"><img src="images/debiasing.png" alt="Debiasing" width="200"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>DebiasBench: Benchmark for Fair Comparison of Debiasing in Image Classification</papertitle>
                <div style="line-height:50%;">
                    <br>
                </div>
              Jungsoo Lee, Juyoung Lee, <u><strong>Sanghun Jung</strong></u>, and Jaegul Choo
              <br>
              <em>Preprint</em>, 2023 &nbsp
              <br>
              <a href="https://arxiv.org/abs/2206.03680">arXiv</a>
            </td>
          </tr>

          <tr> <!-- bgcolor="#ffffd0"-->
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="images/CG_NeRF.png"><img src="images/CG_NeRF.png" alt="Conditional Generative NeRF" width="200"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>CG-NeRF: Conditional Generative Neural Radiance Fields</papertitle>
                <div style="line-height:50%;">
                    <br>
                </div>
              Kyungmin Jo*, Gyumin Shim*, <u><strong>Sanghun Jung</strong></u>, Soyoung Yang, and Jaegul Choo
              <br>
              <strong><em>WACV</em></strong>, 2023 &nbsp
              <br>
              <a href="https://arxiv.org/abs/2112.03517">arXiv</a>
            </td>
          </tr>
          <tr> <!-- bgcolor="#ffffd0"-->
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="images/3dgif.png"><img src="images/3dgif.png" alt="3D-GIF" width="200"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>3D-GIF: 3D-Controllable Object Generation via Implicit Factorized Representations with Unposed 2D Images</papertitle>
                <div style="line-height:50%;">
                    <br>
                </div>
              Minsoo Lee, Chaeyeon Chung, Hojun Cho, Minjung Kim, <u><strong>Sanghun Jung</strong></u>, Minhyuk Sung, and Jaegul Choo
              <br>
              <em>Preprint</em>, 2022 &nbsp
              <br>
              <a href="https://arxiv.org/abs/2203.06457">arXiv</a>
            </td>
          </tr>
          <tr> <!-- bgcolor="#ffffd0"-->
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="images/SML.png"><img src="images/SML.png" alt="SML" width="200" ></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Standardized Max Logits: A Simple yet Effective Approach for Identifying Unexpected Road Obstacles in Urban-Scene Segmentation</papertitle>
                <div style="line-height:50%;">
                    <br>
                </div>
              <u><strong>Sanghun Jung*</strong></u>, Jungsoo Lee*, Daehoon Gwak, Sungha Choi, and Jaegul Choo
              <br>
              <strong><em>ICCV</em></strong>, 2021 &nbsp <font color="red"><strong>Oral Presentation (<3.0%)</strong></font>
              <br>
              <a href="https://arxiv.org/abs/2107.11264">arXiv</a>
                          /
              <a href="https://github.com/shjung13/Standardized-max-logits">code</a>
              <p></p>
            </td>
          </tr>

          <tr> <!-- bgcolor="#ffffd0"-->
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="images/RobustNet.png"><img src="images/RobustNet.png" alt="RobustNet" width="200" ></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>RobustNet: Improving Domain Generalization in Urban-Scene Segmentation via Instance Selective Whitening</papertitle>
                <div style="line-height:50%;">
                    <br>
                </div>
              Sungha Choi*, <u><strong>Sanghun Jung*</strong></u>, Huiwon Yun, Joanne Taery Kim, and Jaegul Choo
              <br>
              <strong><em>CVPR</em></strong>, 2021 &nbsp <font color="red"><strong>Oral Presentation (<4.1%)</strong></font>
              <br>
              <a href="https://arxiv.org/abs/2103.15597">arXiv</a>
                            /
              <a href="https://github.com/shachoi/RobustNet">code</a>
              <p></p>
            </td>
          </tr>
         <tr> <!-- bgcolor="#ffffd0"-->
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="images/vistononvis.png"><img src="images/vistononvis.png" alt="Visualiation for Non-Visuals" width="200" ></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Visualizing for the Non-Visual: Enabling the Visually Impaired to Use Visualization</papertitle>
                <div style="line-height:50%;">
                    <br>
                </div>
              Jinho Choi, <u><strong>Sanghun Jung</strong></u>, Deokgun Park, Jaegul Choo, and Niklas Elmqvist
              <br>
              <strong><em>EuroVIS</em></strong>, 2019
              <br>
              <p></p>
            </td>
          </tr>
        </tbody></table>
        <hr class="soft"/>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10"><tbody>
          <tr>
            <td>
              <heading>Work Experience</heading>
              <br>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="https://amazon.jobs/en/teams/lab126/"/><img src="images/lab126_logo.jpeg" alt="Amazon Lab126" width="100" ></a>
            </td>
            <td width="75%" valign="center">
              <papertitle style="color:gray">
                <big>Applied Scientist Intern - Summer 2025</big>
              </papertitle>
              <papertitle>
                <big> | Amazon Lab126 </big>
              </papertitle>
              <br>
              Sunnyvale, CA  |  Jun. 2025 ~ Sep. 2025
              <ul>
                <li>
                  3D Understanding
                </li>
                <li>
                  Vision-language model / Large-language model
                </li>
              </ul>
            </td>
          </tr>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="https://amazon.jobs/en/teams/lab126/"/><img src="images/lab126_logo.jpeg" alt="Amazon Lab126" width="100" ></a>
            </td>
            <td width="75%" valign="center">
              <!--a href="https://www.bearrobotics.ai/">Robotics Software Engineer, Seoul, South Korea</a-->
              <papertitle style="color:gray">
                <big>Applied Scientist Intern - Summer 2024</big>
              </papertitle>
              <papertitle>
                <big> | Amazon Lab126 </big>
              </papertitle>
              <br>
              Bellevue, WA  |  Jun. 2024 ~ Sep. 2024
              <ul>
                <li>
                  Open-vocabulary instance segmentation
                </li>
                <li>
                  Indoor navigation
                </li>
                <li>
                  Vision-language model / Large-language model
                </li>
              </ul>
            </td>
          </tr>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="https://www.bearrobotics.ai/"/><img src="images/BearRobotics.jpg" alt="BearRobotics" width="100" ></a>
            </td>
            <td width="75%" valign="center">
              <!--a href="https://www.bearrobotics.ai/">Robotics Software Engineer, Seoul, South Korea</a-->
              <papertitle style="color:gray">
                <big>Robotics Engineer</big>
              </papertitle>
              <papertitle>
                <big> | BearRobotics Korea, Inc.</big>
              </papertitle>
              <br>
              Seoul, South Korea  |  Apr. 2019 ~ Jul. 2020
              <ul>
                <li>
                  Safe velocity controller
                </li>
                <li>
                  Odometry and localization testing
                </li>
                <li>
                  Automated simulation testing infrastructure
                </li>
              </ul>
            </td>
          </tr>
          <tr>
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="https://www.bearrobotics.ai/"/><img src="images/BearRobotics.jpg" alt="BearRobotics" width="100" ></a>
            </td>
            <td width="75%" valign="center">
              <!--a href="https://www.bearrobotics.ai/">BearRobotics, Inc.  Redwood City, CA, USA</a -->
              <papertitle style="color:gray">
                <big>Robotics Engineering Intern</big>
              </papertitle>
              <papertitle>
                <big> | BearRobotics, Inc.</big>
              </papertitle>
              <br>
              Redwood City, CA, US  |  Jul. 2018 ~ Mar. 2019
              <ul>
                <li>
                  Depth camera extrinsic calibration
                </li>
              </ul>
            </td>
          </tr>
        </tbody></table>
        <hr class="soft"/>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10"><tbody>
          <tr>
            <td>
              <heading>Invited Talk</heading>
              <br>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <img src="images/CoRL.jpg" alt="Conference on Robot Learning" width="130" >
            </td>
            <td width="75%" valign="center">
              <papertitle>
                <big>2nd Pre-Training for Robot Learning Workshop @ CoRL 2023</big>
              </papertitle>
              <br>
              <ul>
                <li>
                  Gave a spotlight talk about image-based traversability for off-road navigation
                </li>
              </ul>
            </td>
          </tr>
          <tr>
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <img src="images/Naver_AI_Lab.png" alt="Naver AI LAB" width="130" >
            </td>
            <td width="75%" valign="center">
              <papertitle>
                <big>Naver AI LAB</big>
              </papertitle>
              <br>
              <ul>
                <li>
                  Guest speaker for corporate seminar (RobustNet)
                </li>
              </ul>
            </td>
          </tr>
          <tr>
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <img src="images/Hyundai.png" alt="Hyundai Research" width="130" >
            </td>
            <td width="75%" valign="center">
              <papertitle>
                <big>Hyundai Motor Group AI Research Seminar</big>
              </papertitle>
              <br>
              <ul>
                <li>
                  Guest speaker for corporate seminar (RobustNet)
                </li>
              </ul>
            </td>
          </tr>
        </table>
        <hr class="soft"/>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                This website is adapted from Jon Barron's template.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>

<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Sanghun Jung</title>
  
  <meta name="author" content="Sanghun Jung">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!--link rel="icon" type="image/png" href="images/seal_icon.png"-->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Sanghun Jung</name>
              </p><br>
              <p>I am an M.S. candidate at KAIST AI, advised by Prof. Jaegul Choo.
              </p>
              <p>
               At KAIST, I've addressed two problems, domain generalization and out-of-distribution detection in semantic segmentation. Before starting my Master's study, I worked at BearRobotics as a robotics software engineer for two years. I developed robot algorithms such as camera extrinsic calibration, odometry calibration, safe velocity controller, and auto testing simulation infrastructure.
              </p>
              <p style="text-align:center">
                Mail: shjung13 [at] kaist [dot] ac [dot] kr
              </p>
              <p style="text-align:center">
                <a href="data/CV-SanghunJung.pdf">CV</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/sanghun-jung-b17a4b1b8/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=e7X7O8gAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/shjung13/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/SanghunJung.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/SanghunJung_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding-left:20px;padding-bottom:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr> <!-- bgcolor="#ffffd0"-->
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <img src="images/ICCV_interview1.png" alt="ICCV_interview" width="200">
            </td>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <papertitle>Jungsoo and I had an interview at ICCV Daily magazine about our recent paper!</papertitle><br>
              <a href="data/ICCV_interview.pdf"> [article] </a>
              <!--br>
              <strong>Sanghun Jung*</strong>, <a href="https://scholar.google.com/citations?hl=en&user=qSGLUDQAAAAJ">Jungsoo Lee*</a>, <a href="https://scholar.google.com/citations?hl=en&user=NyQ42l8AAAAJ">Daehoon Gwak</a>, <a href="https://scholar.google.com/citations?user=JMTnthsAAAAJ&hl=en">Sungha Choi</a>, and <a href="https://scholar.google.com/citations?user=GHJYsLEAAAAJ&hl=en">Jaegul Choo</a>
              <br>
							<em>ICCV</em>, 2021 &nbsp <font color="red"><strong>Oral Presentation (<3%)</strong></font>
              <br>
              <a href="https://arxiv.org/abs/2103.13415">arXiv</a>
							/
              <a href="https://github.com/shjung13/Standardized-max-logits">code</a>
              <p></p>
              <p>A simple yet effective approach for out-of-distribution detection in semantic segmentation. Based on the finding that max logits have their own range according to their predicted classes, we standardize them, which enables them to reflect their relative meaning in their predicted classes.</p>-->
            </td>
          </tr>
        </tbody></table>
        <hr class="soft">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr> <!-- bgcolor="#ffffd0"-->
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="images/CG_NeRF.png"><img src="images/CG_NeRF.png" alt="Conditional Generative NeRF" width="200"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2107.11264">
                <papertitle>CG-NeRF: Conditional Generative Neural Radiance Fields</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=zyFvIS8AAAAJ&hl=en">Kyungmin Jo*</a>, <a href="https://scholar.google.com/citations?user=lPhbbD8AAAAJ&hl=ko">Gyumin Shim*</a>, <strong>Sanghun Jung</strong>, <a href="https://scholar.google.com/citations?user=5Mw3sVAAAAAJ&hl=ko">Soyoung Yang</a>, and <a href="https://scholar.google.com/citations?user=GHJYsLEAAAAJ&hl=en">Jaegul Choo</a>
              <br>
              <em>Preprint</em>, 2021 &nbsp
              <br>
              <a href="https://arxiv.org/abs/2112.03517">arXiv</a>
              <!--p>A simple yet effective approach for out-of-distribution detection in semantic segmentation. Based on the finding that max logits have their own range according to their predicted classes, we standardize them, which enables them to reflect their relative meaning in their predicted classes.</p-->
            </td>
          </tr>
          <tr> <!-- bgcolor="#ffffd0"-->
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="images/SML.png"><img src="images/SML.png" alt="SML" width="200" ></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2107.11264">
                <papertitle>Standardized Max Logits: A Simple yet Effective Approach for Identifying Unexpected Road Obstacles in Urban-Scene Segmentation</papertitle>
              </a>
              <br>
              <strong>Sanghun Jung*</strong>, <a href="https://scholar.google.com/citations?hl=en&user=qSGLUDQAAAAJ">Jungsoo Lee*</a>, <a href="https://scholar.google.com/citations?hl=en&user=NyQ42l8AAAAJ">Daehoon Gwak</a>, <a href="https://scholar.google.com/citations?user=JMTnthsAAAAJ&hl=en">Sungha Choi</a>, and <a href="https://scholar.google.com/citations?user=GHJYsLEAAAAJ&hl=en">Jaegul Choo</a>
              <br>
							<em>ICCV</em>, 2021 &nbsp <font color="red"><strong>Oral Presentation (<3.0%)</strong></font>
              <br>
              <a href="https://arxiv.org/abs/2103.13415">arXiv</a>
							/
              <a href="https://github.com/shjung13/Standardized-max-logits">code</a>
              <p></p>
              <!--p>A simple yet effective approach for out-of-distribution detection in semantic segmentation. Based on the finding that max logits have their own range according to their predicted classes, we standardize them, which enables them to reflect their relative meaning in their predicted classes.</p-->
            </td>
          </tr>

          <tr> <!-- bgcolor="#ffffd0"-->
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="images/RobustNet.png"><img src="images/RobustNet.png" alt="RobustNet" width="200" ></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2103.15597">
                <papertitle>RobustNet: Improving Domain Generalization in Urban-Scene Segmentation via Instance Selective Whitening</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=JMTnthsAAAAJ&hl=en">Sungha Choi*</a>, <strong>Sanghun Jung*</strong>, Huiwon Yun, <a href="https://scholar.google.com/citations?user=LWfBEPsAAAAJ&hl=en">Joanne Taery Kim</a>, and <a href="https://scholar.google.com/citations?user=GHJYsLEAAAAJ&hl=en">Jaegul Choo</a>
              <br>
							<em>CVPR</em>, 2021 &nbsp <font color="red"><strong>Oral Presentation (<4.1%)</strong></font>
              <br>
              <a href="https://arxiv.org/abs/2103.15597">arXiv</a>
							/
              <a href="https://github.com/shachoi/RobustNet">code</a>
              <p></p>
              <!--p>Enhancing the generalization performance of deep neural networks is crucial for safety-critical applications such as autonomous driving. Hence, we propose a novel Instance Selective Whitening Loss that disentangles the domain-specific style and domain-invariant content encoded in the higher-order statistics.</p-->
            </td>
          </tr>
         <tr> <!-- bgcolor="#ffffd0"-->
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="images/vistononvis.png"><img src="images/vistononvis.png" alt="Visualiation for Non-Visuals" width="200" ></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://users.umiacs.umd.edu/~elm/projects/vis4nonvisual/vis4nonvisual.pdf">
                <papertitle>Visualizing for the Non-Visual: Enabling the Visually Impaired
to Use Visualization</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=4cz0fdoAAAAJ&hl=en">Jinho Choi</a>, <strong>Sanghun Jung</strong>, <a href="https://scholar.google.com/citations?user=cK1bhQUAAAAJ&hl=en">Deokgun Park</a>, <a href="https://scholar.google.com/citations?user=GHJYsLEAAAAJ&hl=en">Jaegul Choo</a>, and <a href="https://scholar.google.com/citations?user=LoQXe24AAAAJ&hl=en">Niklas Elmqvist</a>
              <br>
							<em>EuroVIS</em>, 2019
              <br>
              <!--p>The majority of visualizations on the web are still stored as raster images, making them inaccessible to visually impaired users. We propose a deep-neural-network-based approach that automatically recognizes key elements in visualization and the original data conveyed in the visualization. We leverage such extracted information to provide the reading to visually impaired people via Screen Reader built as a Chrome Extension.</p-->
              <p></p>
            </td>
          </tr>

        </tbody></table>
        <hr class="soft">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Patents</heading>
              <br>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="https://www.bearrobotics.ai/"/><img src="images/BearRobotics.jpg" alt="BearRobotics" width="100" ></a>
            </td>
            <td width="75%" valign="center">
              <strong>Method, System, and Non-Transitory Computer-Readable Recording Medium for Controlling a Robot</strong>
              <br>
              <strong>Sanghun Jung</strong>, Henry L. Leinhos, Fangwei Li, and Ina Liu.
              <br>
              <br>
              US Patent In Progress
            </td>
          </tr>
          <tr>
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="https://www.bearrobotics.ai/"/><img src="images/BearRobotics.jpg" alt="BearRobotics" width="100" ></a>
            </td>
            <td width="75%" valign="center">
              <strong>Method, System, and Non-Transitory Computer-Readable Recording Medium for Controlling Movement of a Robot</strong>
              <br>
              Bryant L. Pong, Henry L. Leinhos, and <strong>Sanghun Jung</strong>
              <br>
              <br>
              US Patent In Progress
            </td>
          </tr>
        </tbody></table>
        <hr class="soft"/>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10"><tbody>
          <tr>
            <td>
              <heading>Work Experience</heading>
              <br>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="https://www.bearrobotics.ai/"/><img src="images/BearRobotics.jpg" alt="BearRobotics" width="100" ></a>
            </td>
            <td width="75%" valign="center">
              <!--a href="https://www.bearrobotics.ai/">Robotics Software Engineer, Seoul, South Korea</a-->
              <papertitle style="color:gray">
                <big>Robotics Engineer</big>
              </papertitle>
              <papertitle>
                <big> | BearRobotics Korea, Inc.</big>
              </papertitle>
              <br>
              Seoul, South Korea  |  Apr. 2019 ~ Jul. 2020
              <ul>
                <li>
                  Safe velocity controller
                </li>
                <li>
                  Odometry and localization testing
                </li>
                <li>
                  Automated simulation testing infrastructure
                </li>
              </ul>
            </td>
          </tr>
          <tr>
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <a href="https://www.bearrobotics.ai/"/><img src="images/BearRobotics.jpg" alt="BearRobotics" width="100" ></a>
            </td>
            <td width="75%" valign="center">
              <!--a href="https://www.bearrobotics.ai/">BearRobotics, Inc.  Redwood City, CA, USA</a -->
              <papertitle style="color:gray">
                <big>Robotics Engineering Intern</big>
              </papertitle>
              <papertitle>
                <big> | BearRobotics, Inc.</big>
              </papertitle>
              <br>
              Redwood City, CA, US  |  Jul. 2018 ~ Mar. 2019
              <ul>
                <li>
                  Depth camera extrinsic calibration
                </li>
              </ul>
            </td>
          </tr>
        </tbody></table>
        <hr class="soft"/>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10"><tbody>
          <tr>
            <td>
              <heading>Invited Talk</heading>
              <br>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <img src="images/Hyundai.png" alt="Hyundai Research" width="130" >
            </td>
            <td width="75%" valign="center">
              <papertitle>
                <big>Hyundai Motor Group AI Research Seminar</big>
              </papertitle>
              <br>
              <ul>
                <li>
                  Guest speaker for corporate seminar (RobustNet)
                </li>
              </ul>
            </td>
          </tr>
          <tr>
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <img src="images/Naver_AI_Lab.png" alt="Naver AI LAB" width="130" >
            </td>
            <td width="75%" valign="center">
              <papertitle>
                <big>Naver AI LAB</big>
              </papertitle>
              <br>
              <ul>
                <li>
                  Guest speaker for corporate seminar (RobustNet)
                </li>
              </ul>
            </td>
        </table>
        <hr class="soft"/>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10"><tbody>
          <tr>
            <td>
              <heading>Extra-Curricular Activities</heading>
              <br>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding-left:40px;padding-top:7px;padding-bottom:7px;width:25%;vertical-align:middle">
              <img src="images/DAVIAN.png" alt="DAVIAN Lab, KAIST AI" width="100" >
            </td>
            <td width="75%" valign="center">
              <papertitle style="color:gray">
                <big>GPU Server Maintainer</big>
              </papertitle>
              <papertitle>
                <big> | DAVIAN Lab., KAIST AI</big>
              </papertitle>
              <br>
              Seongnam, South Korea  |  Aug. 2020 ~
              <br>
              <br>
              Managing Linux GPU servers in DAVIAN Laboratory. We built a server monitoring and auto-reporting system using Linux shell scripts and python.
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                This website is adapted from Jon Barron's template. <a href="https://github.com/jonbarron/jonbarron_website">source code</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
